{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSSINQve+mFOxtjbBQTDHB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uzl/DySys-ML/blob/main/KoopmanNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xzYNq9efJGB6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KoopmanNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple feedforward neural network to estimate Koopman operator embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, embedding_dim):\n",
        "        super(KoopmanNetwork, self).__init__()\n",
        "        # Define the network layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, embedding_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "        self.koopman_layer = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode the input to an embedding\n",
        "        embedding = self.encoder(x)\n",
        "        # Apply the Koopman layer\n",
        "        koopman_embedding = self.koopman_layer(embedding)\n",
        "        # Decode the embedding back to the original space\n",
        "        reconstruction = self.decoder(koopman_embedding)\n",
        "        return embedding, koopman_embedding, reconstruction\n"
      ],
      "metadata": {
        "id": "WJtAmNaaJQxl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_koopman_network(network, data, lag_time, epochs=100, learning_rate=1e-3):\n",
        "    optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for i in range(data.size(0) - lag_time):\n",
        "            # Prepare the inputs and targets\n",
        "            x = data[i]\n",
        "            y = data[i + lag_time]\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            _, koopman_embedding, _ = network(x)\n",
        "\n",
        "            # Compute loss using the Koopman embedding and the target\n",
        "            loss = criterion(koopman_embedding, network.encoder(y))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Print the average loss every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss / (data.size(0) - lag_time)}')\n",
        "\n",
        "    print('Training complete')\n"
      ],
      "metadata": {
        "id": "QOBX7-bmJKFX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "\n",
        "# Synthetic example data: 100 time steps, 3 features (like the Lorenz system)\n",
        "trajectory_data = torch.randn(100, 3)\n",
        "\n",
        "# Define the input dimension (number of features) and the desired embedding dimension\n",
        "input_dim = trajectory_data.size(1)\n",
        "embedding_dim = 64  # This can be chosen based on the problem\n",
        "\n",
        "# Create the Koopman network instance\n",
        "koopman_net = KoopmanNetwork(input_dim=input_dim, embedding_dim=embedding_dim)\n",
        "\n",
        "# Train the network on the trajectory data\n",
        "lag_time = 1  # Set the lag time for the Koopman operator estimation\n",
        "train_koopman_network(koopman_net, trajectory_data, lag_time, epochs=100, learning_rate=1e-3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzrn8S0qJVbJ",
        "outputId": "e731d400-4364-4c9d-ca72-fb1856e02f3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 0.0005426348098541958\n",
            "Epoch 20/100, Loss: 0.0008521540117781666\n",
            "Epoch 30/100, Loss: 0.0003028472215513407\n",
            "Epoch 40/100, Loss: 0.0003063631932426954\n",
            "Epoch 50/100, Loss: 0.00016120568761834875\n",
            "Epoch 60/100, Loss: 0.00015346130675599777\n",
            "Epoch 70/100, Loss: 0.00010848695729701013\n",
            "Epoch 80/100, Loss: 7.259551481790065e-05\n",
            "Epoch 90/100, Loss: 5.8873127631104026e-05\n",
            "Epoch 100/100, Loss: 3.089531320816751e-05\n",
            "Training complete\n"
          ]
        }
      ]
    }
  ]
}